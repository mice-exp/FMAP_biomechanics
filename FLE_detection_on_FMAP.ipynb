{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af17c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "from scipy.signal import butter, filtfilt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95248c32",
   "metadata": {},
   "source": [
    "##### Gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmmp_dir_pwp = './PWP'\n",
    "fma_pwp = glob(os.path.join(mmmp_dir_pwp, '**/FMA*_P[0-9]*.tsv'), recursive=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77367afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tug_dir_pwp = r\"\\TUG\\PWP\"\n",
    "tug_data_pwp = glob(os.path.join(tug_dir_pwp, '**/TUG02_P[0-9]*.tsv'), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c3ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAN_special = -999999\n",
    "def check_file(file):\n",
    "    # Load the motion capture data into a Pandas DataFrame\n",
    "    df = pd.read_csv(file,sep = '\\t',skiprows=11)\n",
    "    df = df.fillna(NAN_special)\n",
    "    df.columns = df.columns.str.strip() #eliminating unecesary spaces in column titles\n",
    "    \n",
    "    marker_list = ['RWRA X', 'RWRA Y', 'RWRA Z','LWRA X', 'LWRA Y', 'LWRA Z',\n",
    "                   'RSHO X', 'RSHO Y', 'RSHO Z', 'LSHO X', 'LSHO Y','LSHO Z',\n",
    "                  'LHEE X', 'LHEE Y', 'LHEE Z','RHEE X', 'RHEE Y', 'RHEE Z'\n",
    "                   ,'LTOE X', 'LTOE Y', 'LTOE Z','RTOE X', 'RTOE Y', 'RTOE Z',\n",
    "                   'STRN X', 'STRN Y', 'STRN Z',\n",
    "                   'LASI X', 'LASI Y', 'LASI Z', 'RASI X', 'RASI Y', 'RASI Z',\n",
    "                  'LELB X', 'LELB Y', 'LELB Z', 'RELB X', 'RELB Y', 'RELB Z']\n",
    "    flag = False # this falg will help us identify the files that are incomplete later \n",
    "    for col_name in marker_list:\n",
    "        if col_name not in df.columns:\n",
    "            flag = True\n",
    "            # print('File: {} , does not have marker {}'.format(file, col_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8622d70a",
   "metadata": {},
   "source": [
    "##### Function to read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAN_special = -999999\n",
    "\n",
    "def read_walking_file(file):\n",
    "    # Load the motion capture data into a Pandas DataFrame\n",
    "    df = pd.read_csv(file,sep = '\\t',skiprows=11)\n",
    "    df = df.fillna(NAN_special)\n",
    "    df.columns = df.columns.str.strip() #eliminating unecesary spaces in column titles\n",
    "    \n",
    "    time = df.loc[:, \"Time\"].to_numpy()\n",
    "    \n",
    "#     subject_id, walk_phase = subject_id_walk_phase.split('_')[0],subject_id_walk_phase.split('_')[1]\n",
    "\n",
    "    marker_list = ['RWRA X', 'RWRA Y', 'RWRA Z', 'LWRA X', 'LWRA Y', 'LWRA Z',\n",
    "                   'RSHO X', 'RSHO Y', 'RSHO Z', 'LSHO X', 'LSHO Y', 'LSHO Z',\n",
    "                   'LHEE X', 'LHEE Y', 'LHEE Z', 'RHEE X', 'RHEE Y', 'RHEE Z',\n",
    "                   'LTOE X', 'LTOE Y', 'LTOE Z', 'RTOE X', 'RTOE Y', 'RTOE Z',\n",
    "                   'STRN X', 'STRN Y', 'STRN Z',\n",
    "                   'LASI X', 'LASI Y', 'LASI Z', 'RASI X', 'RASI Y', 'RASI Z',\n",
    "                   'LELB X', 'LELB Y', 'LELB Z', 'RELB X', 'RELB Y', 'RELB Z',\n",
    "                   'LANK X', 'LANK Y', 'LANK Z', 'RANK X', 'RANK Y', 'RANK Z']\n",
    "\n",
    "    # Create empty arrays for each marker\n",
    "    RSHO = np.zeros((len(time), 3))\n",
    "    LSHO = np.zeros((len(time), 3))\n",
    "    RWRA = np.zeros((len(time), 3))\n",
    "    LWRA = np.zeros((len(time), 3))\n",
    "    LHEE = np.zeros((len(time), 3))\n",
    "    RHEE = np.zeros((len(time), 3))\n",
    "    LTOE = np.zeros((len(time), 3))\n",
    "    RTOE = np.zeros((len(time), 3))\n",
    "    STRN = np.zeros((len(time), 3))\n",
    "    LASI = np.zeros((len(time), 3))\n",
    "    RASI = np.zeros((len(time), 3))\n",
    "    LELB = np.zeros((len(time), 3))\n",
    "    RELB = np.zeros((len(time), 3))\n",
    "    LANK = np.zeros((len(time), 3))\n",
    "    RANK = np.zeros((len(time), 3))\n",
    "\n",
    "    flag = False # this flAg will help us identify the files that are incomplete later \n",
    "    missing_markers = [] # this is a list to collect the missing markers in the file\n",
    "\n",
    "    for col_name in marker_list:\n",
    "        if col_name in df.columns:\n",
    "\n",
    "            if col_name.startswith('RSHO'):\n",
    "                RSHO = df.loc[:, ['RSHO X', 'RSHO Y', 'RSHO Z']].to_numpy()\n",
    "            elif col_name.startswith('LSHO'):\n",
    "                LSHO = df.loc[:, ['LSHO X', 'LSHO Y', 'LSHO Z']].to_numpy()\n",
    "            elif col_name.startswith('RWRA'):\n",
    "                RWRA = df.loc[:, ['RWRA X', 'RWRA Y', 'RWRA Z']].to_numpy()\n",
    "            elif col_name.startswith('LWRA'):\n",
    "                LWRA = df.loc[:, ['LWRA X', 'LWRA Y', 'LWRA Z']].to_numpy()\n",
    "            elif col_name.startswith('LHEE'):\n",
    "                LHEE = df.loc[:, ['LHEE X', 'LHEE Y', 'LHEE Z']].to_numpy()\n",
    "            elif col_name.startswith('RHEE'):\n",
    "                RHEE = df.loc[:, ['RHEE X', 'RHEE Y', 'RHEE Z']].to_numpy()\n",
    "            elif col_name.startswith('LTOE'):\n",
    "                LTOE = df.loc[:, ['LTOE X', 'LTOE Y', 'LTOE Z']].to_numpy()\n",
    "            elif col_name.startswith('RTOE'):\n",
    "                RTOE = df.loc[:, ['RTOE X', 'RTOE Y', 'RTOE Z']].to_numpy()\n",
    "            elif col_name.startswith('STRN'):\n",
    "                STRN = df.loc[:, ['STRN X', 'STRN Y', 'STRN Z']].to_numpy()\n",
    "            elif col_name.startswith('LASI'):\n",
    "                LASI = df.loc[:, ['LASI X', 'LASI Y', 'LASI Z']].to_numpy()\n",
    "            elif col_name.startswith('RASI'):\n",
    "                RASI = df.loc[:, ['RASI X', 'RASI Y', 'RASI Z']].to_numpy()\n",
    "            elif col_name.startswith('LELB'):\n",
    "                LELB = df.loc[:, ['LELB X', 'LELB Y', 'LELB Z']].to_numpy()\n",
    "            elif col_name.startswith('RELB'):\n",
    "                RELB = df.loc[:, ['RELB X', 'RELB Y', 'RELB Z']].to_numpy()\n",
    "            elif col_name.startswith('LANK'):\n",
    "                LANK = df.loc[:, ['LANK X', 'LANK Y', 'LANK Z']].to_numpy()\n",
    "            elif col_name.startswith('RANK'):\n",
    "                RANK = df.loc[:, ['RANK X', 'RANK Y', 'RANK Z']].to_numpy()\n",
    "        else:\n",
    "            flag = True\n",
    "            missing_markers.append(col_name)\n",
    "    print('File: {} , does not have markers {}'.format(file, missing_markers))\n",
    "    \n",
    "    return missing_markers, time, RSHO, LSHO, RWRA, LWRA, LHEE, RHEE, LTOE, RTOE, STRN, LASI, RASI, LELB, RELB, LANK, RANK#, subject_id, walk_phase\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd3d60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_markers, t, RSHO, LSHO, RWRA, LWRA, LHEE, RHEE, LTOE, RTOE, STRN, LASI, RASI, LELB, RELB, LANK, RANK = read_walking_file(fma_pwp[-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777af046",
   "metadata": {},
   "source": [
    "### Walking speed (Cowie et al., 2012)\n",
    "    Calculated with the pelvis midpoint in the walking direction.\n",
    "    Freeze Like Episode: period in which velocity drops below 10% of baseline. (what is baseline in our case?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b9644",
   "metadata": {},
   "outputs": [],
   "source": [
    " def smooth_and_clean_velocity(position_data, time_data, cutoff_freq=5, fs=100):\n",
    "    \"\"\"\n",
    "    Smooths position data and calculates clean velocity\n",
    "    \n",
    "    Args:\n",
    "        position_data: Position data in meters\n",
    "        time_data: Time stamps\n",
    "        cutoff_freq: Cutoff frequency for low-pass filter (Hz)\n",
    "        fs: Sampling frequency (Hz)\n",
    "    \"\"\"\n",
    "    # First smooth the position data\n",
    "    b, a = butter(4, cutoff_freq/(fs/2), btype='low')\n",
    "    position_smoothed = filtfilt(b, a, position_data)\n",
    "    \n",
    "    # Calculate velocity using central difference\n",
    "    velocity = np.zeros(len(position_smoothed))\n",
    "    velocity[1:-1] = (position_smoothed[2:] - position_smoothed[:-2]) / (time_data[2:] - time_data[:-2])\n",
    "    \n",
    "    # Handle endpoints\n",
    "    velocity[0] = (position_smoothed[1] - position_smoothed[0]) / (time_data[1] - time_data[0])\n",
    "    velocity[-1] = (position_smoothed[-1] - position_smoothed[-2]) / (time_data[-1] - time_data[-2])\n",
    "    \n",
    "    # Apply physiological constraints\n",
    "    max_walking_speed = 2.7  # maximum realistic walking speed in m/s\n",
    "    velocity = np.clip(velocity, -max_walking_speed, max_walking_speed)\n",
    "    \n",
    "    return velocity   \n",
    "\n",
    "def walking_velocity_1d(LASI,RASI,time,missing_markers_list):   \n",
    " \n",
    "    # Check if more than 40% of the markers in y are missing\n",
    "    # if np.sum(LASI[:, 1] == NAN_special) / len(LASI[:, 1]) > 0.4 or np.sum(RASI[:, 1] == NAN_special) / len(RASI[:, 1]) > 0.4:\n",
    "    #     print('More than 40% of the markers in y are missing, assigning walking velocity as 0')\n",
    "    #     return 0, np.zeros_like(LASI[:, 1])\n",
    "\n",
    "    if 'RASI Y' and 'LASI Y' in missing_markers_list:\n",
    "        print('RASI and LASI are missing, assigning walking velocity as 0')\n",
    "        return 0, np.zeros_like(time) # we return a null value in case hip markers are missing\n",
    "\n",
    "    elif 'RASI Y' in missing_markers_list:\n",
    "        print('RASI is missing, assigning pelvis coordinates only with LASI')\n",
    "        y_position_pelvis = LASI[:, 1]\n",
    "\n",
    "    elif 'LASI Y' in missing_markers_list:\n",
    "        print('LASI is missing, assigning pelvis coordinates only with RASI')\n",
    "        y_position_pelvis = RASI[:, 1]\n",
    "\n",
    "    else:\n",
    "        pelvis = (LASI + RASI) / 2 # calculate pelvis as midpoint between LASI and RASI\n",
    "        y_position_pelvis = pelvis[:, 1]    \n",
    "    \n",
    "    # Convert position to meters\n",
    "    y_position_pelvis = y_position_pelvis / 1000  # mm to meters\n",
    "    \n",
    "    # find the peak index in the y-axis / extreme point in y postition to determine return \n",
    "    peak_index = np.argmax(y_position_pelvis)\n",
    "    \n",
    "    # set the threshold as peak value minus 2*std(pelvis in y)\n",
    "    threshold = y_position_pelvis[peak_index] - 2 * np.std(y_position_pelvis)\n",
    "\n",
    "\n",
    "    # Search the left tail starting index\n",
    "    \n",
    "    left_tail_index = peak_index #starting at max point \n",
    "    while left_tail_index > 0 and y_position_pelvis[left_tail_index] > threshold: \n",
    "        left_tail_index -= 1 #move one position backwards until close to threshold\n",
    "\n",
    "    # Search right tail starting index\n",
    "    right_tail_index = peak_index #starting at max point \n",
    "    while right_tail_index < len(y_position_pelvis) - 1 and y_position_pelvis[right_tail_index] > threshold:\n",
    "        right_tail_index += 1 #move one position forward until close to threshold\n",
    "\n",
    "    # Define left and right segments of the pelvis y-position\n",
    "    \n",
    "    left_segment_pos_pelvis = y_position_pelvis[left_tail_index:peak_index]\n",
    "    # print('left tail index:',left_tail_index)\n",
    "    # # print(left_segment_pos_pelvis)\n",
    "    right_segment_pos_pelvis = y_position_pelvis[peak_index:right_tail_index]\n",
    "\n",
    "    # Calculate velocity for each segment, cutting the time vector to match both segments\n",
    "    \n",
    "    if left_tail_index == 0:\n",
    "        print('Departure phase missing on TUG file, defining baseline velocity as the mean of the return segment')\n",
    "        pelvis_velocity_y = np.abs(smooth_and_clean_velocity(right_segment_pos_pelvis, time[peak_index:right_tail_index]))\n",
    "        mean_walking_vel = np.mean(pelvis_velocity_y)\n",
    "    \n",
    "    elif right_tail_index == 0:\n",
    "        print('Return phase missing on TUG file, defining baseline velocity as the mean of the departure segment')\n",
    "        pelvis_velocity_y = smooth_and_clean_velocity(left_segment_pos_pelvis, time[left_tail_index:peak_index])\n",
    "        mean_walking_vel = np.mean(pelvis_velocity_y)\n",
    "    else:\n",
    "        vel_left = smooth_and_clean_velocity(left_segment_pos_pelvis, time[left_tail_index:peak_index])\n",
    "        vel_right = smooth_and_clean_velocity(right_segment_pos_pelvis, time[peak_index:right_tail_index])\n",
    "        pelvis_velocity_y = np.concatenate((vel_left, np.abs(vel_right)))\n",
    "        mean_walking_vel = np.mean(pelvis_velocity_y)\n",
    "            \n",
    "    # print(pelvis_velocity_y.shape)\n",
    "    # plt.plot(pelvis_velocity_y, label='Pelvis Velocity')\n",
    "    # # plt.plot(y_delta_pos_pelvis_left, label='Left Segment')\n",
    "    # # plt.plot(y_delta_pos_pelvis_right, label='Right Segment')\n",
    "    # plt.show()\n",
    "\n",
    "    return mean_walking_vel, pelvis_velocity_y     #both in abs value because of change in direction during return \n",
    "\n",
    "\n",
    "mean_walking_vel,pelvis_velocity_y = walking_velocity_1d(LASI,RASI,t,missing_markers)\n",
    "print(mean_walking_vel)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(pelvis_velocity_y, label='Smoothed Velocity', alpha=0.8)\n",
    "plt.axhline(y=mean_walking_vel, color='r', linestyle='--', label='Mean Velocity')\n",
    "plt.xlabel('Time points')\n",
    "plt.ylabel('Velocity (m/s)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd448d8",
   "metadata": {},
   "source": [
    "## Baseline velocity from TUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8230f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_baseline_walking_file(file):\n",
    "    # Load the motion capture data into a Pandas DataFrame\n",
    "    df = pd.read_csv(file,sep = '\\t',skiprows=11)\n",
    "    df = df.fillna(NAN_special)\n",
    "    df.columns = df.columns.str.strip() #eliminating unecesary spaces in column titles\n",
    "    \n",
    "    time = df.loc[:, \"Time\"].to_numpy()\n",
    "    \n",
    "#     subject_id, walk_phase = subject_id_walk_phase.split('_')[0],subject_id_walk_phase.split('_')[1]\n",
    "\n",
    "    marker_list = ['LASI X', 'LASI Y', 'LASI Z', 'RASI X', 'RASI Y', 'RASI Z']\n",
    "\n",
    "    # Create empty arrays for each marker\n",
    "   \n",
    "    LASI = np.zeros((len(time), 3))\n",
    "    RASI = np.zeros((len(time), 3))\n",
    "    \n",
    "    flag = []\n",
    "    missing_markers = [] \n",
    "\n",
    "    for col_name in marker_list:\n",
    "        if col_name in df.columns:\n",
    "            flag.append(False)\n",
    "            if col_name.startswith('LASI'):\n",
    "                LASI = df.loc[:, ['LASI X', 'LASI Y', 'LASI Z']].to_numpy()\n",
    "            elif col_name.startswith('RASI'):\n",
    "                RASI = df.loc[:, ['RASI X', 'RASI Y', 'RASI Z']].to_numpy()\n",
    "        else:\n",
    "            flag.append(True)\n",
    "            missing_markers.append(col_name)\n",
    "        \n",
    "    print('File: {} , does not have markers {}'.format(file, missing_markers))\n",
    "\n",
    "    return missing_markers, time, LASI, RASI\n",
    "\n",
    "missing_markers, t, LASI, RASI = read_baseline_walking_file(tug_data_pwp[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_velocity_1d(bl_file):\n",
    "    \n",
    "    missing_markers_list, t, LASI, RASI = read_baseline_walking_file(bl_file)\n",
    "\n",
    "    if 'RASI Y' and 'LASI Y' in missing_markers_list:\n",
    "        print('RASI and LASI are missing, assigning baseline velocity as 0')\n",
    "        return baseline_velocity == 0 # we return a null value in case hip markers are missing\n",
    "\n",
    "    elif 'RASI Y' in missing_markers_list:\n",
    "        print('RASI is missing, assigning pelvis coordinates only with LASI')\n",
    "        y_position_pelvis = LASI[:, 1]\n",
    "\n",
    "    elif 'LASI Y' in missing_markers_list:\n",
    "        print('LASI is missing, assigning pelvis coordinates only with RASI')\n",
    "        y_position_pelvis = RASI[:, 1]\n",
    "\n",
    "    else:\n",
    "        pelvis = (LASI + RASI) / 2 # calculate pelvis as midpoint between LASI and RASI\n",
    "        y_position_pelvis = pelvis[:, 1]    \n",
    "    \n",
    "     # Convert position to meters\n",
    "    y_position_pelvis = y_position_pelvis / 1000  # mm to meters\n",
    "    \n",
    "    # find the peak index in the y-axis / extreme point in y postition to determine return \n",
    "    peak_index = np.argmax(y_position_pelvis)\n",
    "    \n",
    "    # set the threshold as peak value minus 2*std(pelvis in y)\n",
    "    threshold = y_position_pelvis[peak_index] - 2 * np.std(y_position_pelvis)\n",
    "\n",
    "    # there might not be left or right tail so we need to check if \n",
    "    # the y pelvis curve corresponds to a gaussian-like curve or not\n",
    "        \n",
    "    # Search the left tail starting index\n",
    "    \n",
    "    left_tail_index = peak_index #starting at max point \n",
    "    while left_tail_index > 0 and y_position_pelvis[left_tail_index] > threshold: \n",
    "        left_tail_index -= 1 #move one position backwards until close to threshold\n",
    "\n",
    "    # Search right tail starting index\n",
    "    right_tail_index = peak_index #starting at max point \n",
    "    while right_tail_index < len(y_position_pelvis) - 1 and y_position_pelvis[right_tail_index] > threshold:\n",
    "        right_tail_index += 1 #move one position forward until close to threshold\n",
    "\n",
    "    # Define left and right segments of the pelvis y-position\n",
    "    \n",
    "    left_segment_pos_pelvis = y_position_pelvis[left_tail_index:peak_index]\n",
    "    # print('left tail index:',left_tail_index)\n",
    "    # # print(left_segment_pos_pelvis)\n",
    "    right_segment_pos_pelvis = y_position_pelvis[peak_index:right_tail_index]\n",
    "\n",
    "    # Calculate the time and position differentials for velocity\n",
    "    time_diff = np.diff(t)\n",
    "\n",
    "    # Calculate velocity for each segment, cutting the time vector to match both segments\n",
    "    \n",
    "    if left_tail_index == 0:\n",
    "        print('Departure phase missing on TUG file, defining baseline velocity as the mean of the return segment')\n",
    "        pelvis_velocity_y = np.abs(smooth_and_clean_velocity(right_segment_pos_pelvis, t[peak_index:right_tail_index]))\n",
    "        return np.mean(pelvis_velocity_y)\n",
    "    \n",
    "    elif right_tail_index == 0:\n",
    "        print('Return phase missing on TUG file, defining baseline velocity as the mean of the departure segment')\n",
    "        pelvis_velocity_y = np.abs(smooth_and_clean_velocity(left_segment_velocity, t[peak_index:right_tail_index]))\n",
    "        return np.mean(pelvis_velocity_y)\n",
    "    else:\n",
    "        vel_left = smooth_and_clean_velocity(left_segment_pos_pelvis, t[left_tail_index:peak_index])\n",
    "        vel_right = smooth_and_clean_velocity(right_segment_pos_pelvis, t[peak_index:right_tail_index])\n",
    "        pelvis_velocity_y = np.concatenate((vel_left, np.abs(vel_right)))\n",
    "        baseline_velocity = np.mean(pelvis_velocity_y)\n",
    "\n",
    "        # plt.plot(vel_left, label='Left Segment')\n",
    "        # plt.plot(np.abs(vel_right), label='Right Segment')\n",
    "        \n",
    "           # Plotting the pelvis position and detected thresholds\n",
    "    #     plt.figure(figsize=(12, 6))\n",
    "    #     plt.plot(t, y_position_pelvis, label='Pelvis Y Position', color='blue')\n",
    "    #     plt.axvline(x=t[peak_index], color='orange', linestyle='--', label='Peak')\n",
    "    #     plt.axvline(x=t[left_tail_index], color='green', linestyle='--', label='Left Tail')\n",
    "    #     plt.axvline(x=t[right_tail_index], color='red', linestyle='--', label='Right Tail')\n",
    "        \n",
    "    #     plt.xlabel('Time (s)')\n",
    "    #     plt.ylabel('Pelvis Y Position (mm)')\n",
    "    #     plt.title('Pelvis Y Position with Left and Right Tail Detection')\n",
    "    #     plt.legend()\n",
    "    #     plt.grid(True)\n",
    "    #     plt.show()\n",
    "    return baseline_velocity\n",
    "\n",
    "baseline_velocity = get_baseline_velocity_1d(tug_data_pwp[-2])\n",
    "print(baseline_velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c46284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axhline(baseline_velocity,label='Baseline velocity',color='red')\n",
    "plt.axhline(baseline_velocity*0.1,label='Threshold',color='green')\n",
    "\n",
    "plt.plot(pelvis_velocity_y,label='Velocity in y-axis')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Velocity m/s')\n",
    "plt.xlabel('Time (s)')\n",
    "# plt.ylim(-0.3,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7e744",
   "metadata": {},
   "source": [
    "# Freeze-like Events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997ce99",
   "metadata": {},
   "source": [
    "Based on the calculation criteria of: Cowie et al., 2012 `\"... defined an FLE as a period in which velocity dropped below 10% of baseline.\" `\n",
    "\n",
    "This code calculates the duration of every FLE, and provides a counts how many FLE are in every trajectory.\n",
    "`A FLE is counted if it has a minimum duration of 0.5 seconds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d99e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fle(baseline_vel,pelvis_velocity_vector,time_vector):\n",
    "    baseline_threshold = 0.1 * baseline_vel \n",
    "    \n",
    "    # Identify FLE points (True where velocity is below 10% of baseline)\n",
    "    is_fle = pelvis_velocity_vector < baseline_threshold\n",
    "\n",
    "    # Find the start and end indices of each FLE\n",
    "    fle_durations = []\n",
    "    fle_count = 0\n",
    "    in_fle = False  # track if we're inside a FLE\n",
    "\n",
    "    for i in range(1, len(is_fle)):\n",
    "        if is_fle[i] and not in_fle:  # Start of a new FLE\n",
    "            fle_start = i\n",
    "            in_fle = True\n",
    "        elif not is_fle[i] and in_fle:  # End of the current FLE\n",
    "            fle_end = i\n",
    "            fle_duration = time_vector[fle_end] - time_vector[fle_start]\n",
    "            if fle_duration >= 0.5: # Threshold: of FLE is long enough = at least 0.5 seconds (to avoid noisy velocity points) - Cowie : no threshold but in graph is as low as 0.1 s\n",
    "                fle_durations.append(fle_duration)\n",
    "                fle_count += 1\n",
    "            else: \n",
    "                 pass\n",
    "            in_fle = False\n",
    "\n",
    "\n",
    "    # Output results with handling for empty fle_durations\n",
    "#     print(f\"Number of FLEs: {fle_count}\")\n",
    "    if fle_durations:\n",
    "        mean_fle_duration = np.mean(fle_durations)\n",
    "#         print(f\"Durations of each FLE (in seconds): {fle_durations}\")\n",
    "#         print(f\"Mean FLE time (in seconds): {np.mean(fle_durations)}\")\n",
    "    else:\n",
    "        mean_fle_duration = 0\n",
    "#         print(\"No freeze-like events detected.\")\n",
    "#     print(fle_durations)\n",
    "            \n",
    "    return fle_count, mean_fle_duration\n",
    "\n",
    "\n",
    "\n",
    "count_fle, mean_fle_time = fle(baseline_velocity,pelvis_velocity_y,t)\n",
    "print(count_fle, mean_fle_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53dae06",
   "metadata": {},
   "source": [
    "## Storing FLE data in dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe6796b",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataframes to store the gait parameters\n",
    "df_fle_fmap = pd.DataFrame(columns=['Subject ID','Group','TrialFMA', \n",
    "                                              'Mean_Walking_velocity[m/s]',\n",
    "                                              'TUG_baseline_velocity[m/s]',\n",
    "                                              'total_FLE','Mean_FLE_duration[s]'\n",
    "                                             ] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5952f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = [fma_control,fma_pwp]\n",
    "# subject_ids = [ids_control,ids_pwp]\n",
    "\n",
    "group_label = ['Control','PwP']\n",
    "# tug_data_pwp = tug_data_pwp\n",
    "\n",
    "for i,group in enumerate(full_data):\n",
    "    for j,file in enumerate(group):\n",
    "        # Obtain labels\n",
    "        g_l = group_label[i]\n",
    "        \n",
    "        # Extract subject ID\n",
    "        if g_l == 'Control':\n",
    "            subject_id = re.search(r'_C(\\d+)\\.tsv$', file).group(1)\n",
    "            subject_id = 'C'+subject_id\n",
    "            color = 'blue'\n",
    "        else: \n",
    "            subject_id = re.search(r'_P(\\d+)\\.tsv$', file).group(1)\n",
    "            subject_id = 'P'+subject_id\n",
    "\n",
    "        \n",
    "        # Extract trial ID\n",
    "        # Extract trial ID with error handling\n",
    "        match = re.search(r'FMA0?(\\d+)_', file)  # '0?' makes the zero optional\n",
    "        if match:\n",
    "            trial = match.group(1)\n",
    "        else:\n",
    "            # Handle missing trial ID (e.g., raise error, log warning, set default)\n",
    "            raise ValueError(f\"Trial ID not found in filename: {file}\")\n",
    "\n",
    "        \n",
    "        # Read file\n",
    "        missing_markers, t, RSHO, LSHO, RWRA, LWRA, LHEE, RHEE, LTOE, RTOE, STRN, LASI, RASI, LELB, RELB, LANK, RANK = read_walking_file(file)\n",
    "       \n",
    "        # # Check if there are markers missing\n",
    "        # if flag[0]==True:\n",
    "        #     print(f'Subject {subject_id}, does not have marker {flag[1]}')\n",
    "            \n",
    "        # # Check for 'departure' suffixes\n",
    "        # for suffix in ['01', '03', '05']:\n",
    "        #     if f'_{suffix}_' in file:\n",
    "        #         code = suffix\n",
    "        #         break  # Stop once a match is found\n",
    "        \n",
    "        # # Check for 'return' suffixes if no 'departure' was found\n",
    "        # else:\n",
    "        #     for suffix in ['02', '04', '06']:\n",
    "        #         if f'_{suffix}_' in file:\n",
    "        #             code = suffix\n",
    "        #             break          \n",
    "            \n",
    "        #------------------------- \n",
    "        #------------------------- WALKING VELOCITY\n",
    "        \n",
    "        mean_walking_vel,pelvis_velocity_y = walking_velocity_1d(LASI,RASI,t,missing_markers)\n",
    "        \n",
    "            # mean_walking_vel,pelvis_velocity_y = np.abs(mean_walking_vel), np.abs(pelvis_velocity_y)\n",
    "        \n",
    "        \n",
    "        #------------------------- \n",
    "        \n",
    "        #------------------------- FLE and BASELINE VELOCITY FROM TUG TASK (ONLY FOR PWP)\n",
    "        if g_l == 'PwP':\n",
    "            # Search the Parciticpant's corresponding TUG file in tug_data_pwp that matches its subject_id\n",
    "            corresponding_file = [f for f in tug_data_pwp \n",
    "                                  if subject_id == f.split(\"\\\\\")[-1].split(\"_\")[-1].split(\".\")[0]]\n",
    "            \n",
    "            \n",
    "            # Check if a corresponding file was found\n",
    "            if corresponding_file:\n",
    "                print(corresponding_file)\n",
    "                # Calculate baseline velocty, save it in baseline_vel \n",
    "                baseline_file = corresponding_file[0]\n",
    "                # print(subject_id)\n",
    "                baseline_vel = get_baseline_velocity_1d(baseline_file)\n",
    "                \n",
    "                # Call the FLE function\n",
    "                \n",
    "                count_fle, mean_fle_time = fle(baseline_vel,pelvis_velocity_y,t)\n",
    "                \n",
    "#                 print(f\"Found corresponding file for {subject_id}: {corresponding_file[0]}\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"No TUG02 file found for {subject_id}\")\n",
    "        else:\n",
    "            # Null values for Controls: \n",
    "            baseline_vel = 0\n",
    "            count_fle = 0\n",
    "            mean_fle_time = 0\n",
    "                    \n",
    "        \n",
    "        #------------------------- \n",
    "        \n",
    "        #------------------------- SAVING DATA IN DF\n",
    "        \n",
    "        new_line = {'Subject ID':subject_id,'Group':g_l,'TrialFMA':trial,\n",
    "                   'Mean_Walking_velocity[m/s]': mean_walking_vel,\n",
    "                    'TUG_baseline_velocity[m/s]':baseline_vel,\n",
    "                    'total_FLE':count_fle,\n",
    "                    'Mean_FLE_duration[s]':mean_fle_time,\n",
    "                        }\n",
    "        \n",
    "        df_fle_fmap.loc[len(df_fle_fmap)] = new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04993a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fle_fmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b4bde",
   "metadata": {},
   "source": [
    "# Merge with covariates for ANCOVA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
